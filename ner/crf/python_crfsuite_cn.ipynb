{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF based NER\n",
    "- [참고 코드](https://lovit.github.io/nlp/2018/06/22/crf_based_ner/)\n",
    "- data : [MSRA](https://github.com/OYE93/Chinese-NLP-Corpus/tree/master/NER/MSRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-crfsuite in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (0.9.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pycrfsuite\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from itertools import chain\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = './data/msra_train_bio.txt'\n",
    "test_set = './data/msra_test_bio.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  데이터 형식\n",
    "- token/ner tagging\n",
    "- 문장 구별은 '\\n' 문자로 되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['当\\tO\\n',\n",
       " '希\\tO\\n',\n",
       " '望\\tO\\n',\n",
       " '工\\tO\\n',\n",
       " '程\\tO\\n',\n",
       " '救\\tO\\n',\n",
       " '助\\tO\\n',\n",
       " '的\\tO\\n',\n",
       " '百\\tO\\n',\n",
       " '万\\tO\\n']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(train_set)\n",
    "f.readlines()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data_preprocessing(file_name):\n",
    "    tagged_sentences = []\n",
    "    sentence = []\n",
    "    with open(file_name,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if len(line) == 0 or line[0] == '\\n':\n",
    "                if len(sentence) > 0:\n",
    "                    tagged_sentences.append(sentence)\n",
    "                    sentence = []\n",
    "                continue\n",
    "            if line =='0\\t\\n':\n",
    "                continue\n",
    "            word, ner_tag = line.strip().split('\\t') \n",
    "            sentence.append((word, ner_tag)) # 단어와 개체명 태깅만 기록\n",
    "    return tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = raw_data_preprocessing(train_set)\n",
    "test_sents = raw_data_preprocessing(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 3442)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents), len(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('胡', 'B-PER'),\n",
       " ('锦', 'I-PER'),\n",
       " ('涛', 'I-PER'),\n",
       " ('欢', 'O'),\n",
       " ('迎', 'O'),\n",
       " ('伊', 'B-PER'),\n",
       " ('利', 'I-PER'),\n",
       " ('埃', 'I-PER'),\n",
       " ('斯', 'I-PER'),\n",
       " ('库', 'I-PER'),\n",
       " ('率', 'O'),\n",
       " ('团', 'O'),\n",
       " ('访', 'O'),\n",
       " ('华', 'B-LOC'),\n",
       " ('，', 'O'),\n",
       " ('并', 'O'),\n",
       " ('表', 'O'),\n",
       " ('示', 'O'),\n",
       " ('相', 'O'),\n",
       " ('信', 'O'),\n",
       " ('此', 'O'),\n",
       " ('次', 'O'),\n",
       " ('来', 'O'),\n",
       " ('访', 'O'),\n",
       " ('将', 'O'),\n",
       " ('对', 'O'),\n",
       " ('两', 'O'),\n",
       " ('党', 'O'),\n",
       " ('、', 'O'),\n",
       " ('两', 'O'),\n",
       " ('国', 'O'),\n",
       " ('关', 'O'),\n",
       " ('系', 'O'),\n",
       " ('的', 'O'),\n",
       " ('发', 'O'),\n",
       " ('展', 'O'),\n",
       " ('起', 'O'),\n",
       " ('到', 'O'),\n",
       " ('促', 'O'),\n",
       " ('进', 'O'),\n",
       " ('作', 'O'),\n",
       " ('用', 'O'),\n",
       " ('。', 'O')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. using PyCRFSuite \n",
    "## PyCRFSuite란?\n",
    "- c++로 구현된 CRFSuite 구현체를 Python 환경에서 이용할 수 있도록 도와주는 라이브러리\n",
    "- 해당 라이브러리를 이용하기위해서는 potential function을 직접 디자인해야 함\n",
    "\n",
    "### potential function\n",
    "- word2features는 문장 sent의 시점 i에 대한 potential function임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(), # word lower\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(), # word is upper?\n",
    "        'word.istitle=%s' % word.istitle(), # word is title?\n",
    "        'word.isdigit=%s' % word.isdigit(), # word is digit?\n",
    "        #'postag=' + postag,\n",
    "        #'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            #'-1:postag=' + postag1,\n",
    "            #'-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            #'+1:postag=' + postag1,\n",
    "            #'+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence to features, labels, tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for  i in range(len(sent))]\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bias',\n",
       " 'word.lower=当',\n",
       " 'word[-3:]=当',\n",
       " 'word[-2:]=当',\n",
       " 'word.isupper=False',\n",
       " 'word.istitle=False',\n",
       " 'word.isdigit=False',\n",
       " 'BOS',\n",
       " '+1:word.lower=希',\n",
       " '+1:word.istitle=False',\n",
       " '+1:word.isupper=False']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 학습 가능한 형태의 데이터로 변환\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the model\n",
    "## 3-1. 주어진 모든 feature를 다 가지고 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 데이터를 append 하여 학습할 준비 함\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq,yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter setting\n",
    "# 최소 다섯번 이상 등장한 feature만 이용\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True,\n",
    "    \n",
    "    # minimum frequency\n",
    "    'feature.minfreq': 5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "model_name = './model/msra_cn.crfsuite'\n",
    "trainer.train(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f9e60479210>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger() # 학습된 모델을 tagger로 불러옴\n",
    "tagger.open(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 跨 世 纪 的 征 途 上 ， 在 中 国 共 产 党 领 导 下 ， 我 们 要 努 力 实 现 包 括 各 民 主 党 派 、 各 人 民 团 体 、 无 党 派 人 士 在 内 的 全 体 中 国 人 民 的 大 团 结 ， 实 现 包 括 大 陆 同 胞 、 台 港 澳 同 胞 和 海 外 侨 胞 在 内 的 所 有 爱 国 的 中 华 儿 女 的 大 团 结 ， 从 而 战 胜 各 种 艰 难 险 阻 ， 实 现 跨 世 纪 的 宏 伟 蓝 图 。\n",
      "\n",
      "Predicted: O, O, O, O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-LOC, O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-LOC, O, O, O, B-LOC, I-LOC, I-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O\n",
      "Correct: O, O, O, O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-LOC, O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-LOC, O, O, O, B-LOC, B-LOC, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, I-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O\n"
     ]
    }
   ],
   "source": [
    "# 테스트 문장에 대하여 ner tagging 수행\n",
    "ex_sent = test_sents[10]\n",
    "print(' '.join(sent2tokens(ex_sent)), end='\\n\\n')\n",
    "print(\"Predicted:\",', '.join(tagger.tag(sent2features(ex_sent))))\n",
    "print(\"Correct:\",', '.join(sent2labels(ex_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tagging performance\n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test\n",
    "y_pred = []\n",
    "for sent in test_sents:\n",
    "    y_pred.append(tagger.tag(sent2features(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n       B-LOC       0.88      0.75      0.81      2886\\n       I-LOC       0.83      0.66      0.74      4405\\n       B-ORG       0.70      0.62      0.66      1331\\n       I-ORG       0.70      0.72      0.71      5646\\n       B-PER       0.92      0.64      0.76      1973\\n       I-PER       0.83      0.83      0.83      3851\\n\\n   micro avg       0.80      0.72      0.75     20092\\n   macro avg       0.81      0.70      0.75     20092\\nweighted avg       0.80      0.72      0.75     20092\\n samples avg       0.08      0.08      0.08     20092\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. 한정된 feature만 가지고 학습\n",
    "- bias, word lower, word[-3:], word[-2:]만 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 학습 가능한 형태의 데이터로 변환\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 데이터를 append 하여 학습할 준비 함\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq,yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter setting\n",
    "# 최소 다섯번 이상 등장한 feature만 이용\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True,\n",
    "    \n",
    "    # minimum frequency\n",
    "    'feature.minfreq': 5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7f9d34bc5690>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model_name = './model/msra_cn_lower_features.crfsuite'\n",
    "trainer.train(model_name)\n",
    "tagger = pycrfsuite.Tagger() # 학습된 모델을 tagger로 불러옴\n",
    "tagger.open(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test\n",
    "y_pred = []\n",
    "for sent in test_sents:\n",
    "    y_pred.append(tagger.tag(sent2features(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n       B-LOC       0.86      0.74      0.79      2886\\n       I-LOC       0.80      0.60      0.69      4405\\n       B-ORG       0.69      0.59      0.64      1331\\n       I-ORG       0.69      0.70      0.70      5646\\n       B-PER       0.91      0.62      0.74      1973\\n       I-PER       0.82      0.83      0.83      3851\\n\\n   micro avg       0.78      0.69      0.73     20092\\n   macro avg       0.80      0.68      0.73     20092\\nweighted avg       0.79      0.69      0.73     20092\\n samples avg       0.08      0.08      0.08     20092\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.모델 확인\n",
    "- 영향력이 높은 features, 각각에 해당하는 weight확인\n",
    "- 3-1에서 모든 feature를 이용했던 모델로 평가\n",
    "- 해당 결과로 ner tagging에서 중요한 정보는 앞/뒤에 등장하는 단어임을 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('+1:word.lower=堂', 'I-LOC') : 3.928522\n",
      "('word[-3:]=淮', 'B-LOC') : 3.210983\n",
      "('word[-2:]=淮', 'B-LOC') : 3.210983\n",
      "('-1:word.lower=赴', 'B-LOC') : 3.190209\n",
      "('-1:word.lower=℃', 'B-LOC') : 3.186736\n",
      "('+1:word.lower=寺', 'I-LOC') : 3.005503\n",
      "('+1:word.lower=运', 'B-LOC') : 2.944599\n",
      "('+1:word.lower=两', 'B-LOC') : 2.904629\n",
      "('-1:word.lower=抗', 'B-LOC') : 2.898436\n",
      "('-1:word.lower=访', 'B-LOC') : 2.879258\n",
      "('-1:word.lower=县', 'B-LOC') : 2.76594\n",
      "('-1:word.lower=拿', 'I-LOC') : 2.662926\n",
      "('-1:word.lower=省', 'B-LOC') : 2.625714\n",
      "('-1:word.lower=报', 'B-LOC') : 2.531602\n",
      "('+1:word.lower=友', 'B-LOC') : 2.464358\n",
      "('+1:word.lower=关', 'B-LOC') : 2.429949\n",
      "('+1:word.lower=球', 'B-LOC') : 2.414464\n",
      "('+1:word.lower=举', 'I-LOC') : 2.401059\n",
      "('-1:word.lower=社', 'B-LOC') : 2.383605\n",
      "('+1:word.lower=村', 'I-LOC') : 2.337183\n",
      "('+1:word.lower=晴', 'I-LOC') : 2.336281\n",
      "('+1:word.lower=州', 'B-LOC') : 2.300002\n",
      "('+1:word.lower=谷', 'B-LOC') : 2.288912\n",
      "('+1:word.lower=双', 'B-LOC') : 2.23587\n",
      "('+1:word.lower=街', 'I-LOC') : 2.203206\n",
      "('-1:word.lower=在', 'B-LOC') : 2.178078\n",
      "('-1:word.lower=驻', 'B-LOC') : 2.167853\n",
      "('+1:word.lower=淮', 'B-LOC') : 2.15182\n",
      "('+1:word.lower=昌', 'B-LOC') : 2.146022\n",
      "('+1:word.lower=剧', 'B-LOC') : 2.134436\n",
      "('+1:word.lower=藏', 'B-LOC') : 2.120293\n",
      "('-1:word.lower=往', 'B-LOC') : 2.098831\n",
      "('+1:word.lower=阳', 'B-LOC') : 2.066426\n",
      "('+1:word.lower=岛', 'I-LOC') : 2.028079\n",
      "('+1:word.lower=６', 'I-LOC') : 1.974101\n",
      "('word[-3:]=圳', 'I-LOC') : 1.910798\n",
      "('word[-2:]=圳', 'I-LOC') : 1.910798\n",
      "('-1:word.lower=讯', 'B-LOC') : 1.894202\n",
      "('word[-3:]=以', 'B-LOC') : 1.891801\n",
      "('word[-2:]=以', 'B-LOC') : 1.891801\n",
      "('word[-3:]=日', 'B-LOC') : 1.870299\n",
      "('word[-2:]=日', 'B-LOC') : 1.870299\n",
      "('+1:word.lower=南', 'B-LOC') : 1.842134\n",
      "('+1:word.lower=圳', 'B-LOC') : 1.838153\n",
      "('word[-3:]=京', 'B-LOC') : 1.825415\n",
      "('word[-2:]=京', 'B-LOC') : 1.825415\n",
      "('word[-3:]=浙', 'B-LOC') : 1.820238\n",
      "('word[-2:]=浙', 'B-LOC') : 1.820238\n",
      "('+1:word.lower=侨', 'B-LOC') : 1.811946\n",
      "('word[-3:]=藏', 'B-LOC') : 1.785536\n"
     ]
    }
   ],
   "source": [
    "debugger = tagger.info()\n",
    "weights = debugger.state_features\n",
    "location_features = {feature:weight for feature, weight in weights.items() if 'LOC' in feature[1]}\n",
    "\n",
    "for feature, weight in sorted(location_features.items(), key=lambda x:-x[1])[:50]:\n",
    "    print('{} : {}'.format(feature, weight))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
