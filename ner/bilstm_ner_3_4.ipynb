{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuTcUpUla5ZW"
   },
   "source": [
    "[참고 사이트](https://wikidocs.net/24682)\n",
    "# 3) 개체명 인식\n",
    "## 2. NLTK를 이용한 개체명 인식(NER using NTLK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UChCLjXFads5",
    "outputId": "a2766c33-b6d0-4835-ceb1-9924acf93efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYDZ4zm9aJby",
    "outputId": "cdd1e3d0-d0e7-462e-a276-fe3053faf9c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bob', 'NNP'),\n",
       " ('have', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('nice', 'JJ'),\n",
       " ('boyfriend', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('London', 'NNP')]"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "sentence = \"Bob have a nice boyfriend in London\"\n",
    "sentence = pos_tag(word_tokenize(sentence))\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIBIOGj9jNPz"
   },
   "source": [
    "- ne_chunk는 개체명을 태깅하기 위해서 앞서 품사 태깅이 수행되어야 함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "gUwKMANhadzw",
    "outputId": "c95ff0d7-2716-4333-fee7-2c39a2e33e8c"
   },
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCanvasFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0m_canvas_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCanvasFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0mwidget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_to_treesegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_canvas_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0m_canvas_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_widget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/draw/util.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, **kw)\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;31m# If no parent was given, set up a top-level window.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NLTK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<Control-p>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2021\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Bob', 'NNP')]), ('have', 'VBP'), ('a', 'DT'), ('nice', 'JJ'), ('boyfriend', 'NN'), ('in', 'IN'), Tree('GPE', [('London', 'NNP')])])"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ne_chunk(sentence)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9EcyiDcjXmb"
   },
   "source": [
    "# 4) 개체명 인식의 BIO 표현 이해하기\n",
    "### 도메인 또는 목적에 특화되도록 개체명 인식을 정확하게 하는 방법\n",
    "- 기존에 공개된 개체명 인식기 사용x\n",
    "- 직접 목적에 맞는 데이터를 준비하여 기계를 훈련시켜 모델을 만드는 방법\n",
    "\n",
    "### 양방향 LSTM을 이용해서 개체명 인식기를 만들어보자\n",
    "\n",
    "## 2. 개체명 인식 데이터 이해하기\n",
    "- 사용데이터 : [CONLL2003](https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/neuroner/data/conll2003/en/train.txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Po9xXJhjWsK",
    "outputId": "9416ce3f-a8a5-4c03-8129-6755a12766ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-13 02:22:00--  https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/neuroner/data/conll2003/en/train.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3283420 (3.1M) [text/plain]\n",
      "Saving to: ‘train.txt.2’\n",
      "\n",
      "train.txt.2         100%[===================>]   3.13M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2021-04-13 02:22:00 (30.3 MB/s) - ‘train.txt.2’ saved [3283420/3283420]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/neuroner/data/conll2003/en/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "M5ehbUuAlZk1"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "#files.download('train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3TaWUzjmNUY"
   },
   "source": [
    "### 데이터 형식\n",
    "- word / pos tagging / chunk tagging / ner tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAqVh_rwln2j",
    "outputId": "7c56b6ed-81d5-4255-a5e5-d9c30b889375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-DOCSTART- -X- -X- O\\n',\n",
       " '\\n',\n",
       " 'EU NNP B-NP B-ORG\\n',\n",
       " 'rejects VBZ B-VP O\\n',\n",
       " 'German JJ B-NP B-MISC\\n',\n",
       " 'call NN I-NP O\\n',\n",
       " 'to TO B-VP O\\n',\n",
       " 'boycott VB I-VP O\\n',\n",
       " 'British JJ B-NP B-MISC\\n',\n",
       " 'lamb NN I-NP O\\n',\n",
       " '. . O O\\n',\n",
       " '\\n',\n",
       " 'Peter NNP B-NP B-PER\\n',\n",
       " 'Blackburn NNP I-NP I-PER\\n',\n",
       " '\\n',\n",
       " 'BRUSSELS NNP B-NP B-LOC\\n',\n",
       " '1996-08-22 CD I-NP O\\n',\n",
       " '\\n',\n",
       " 'The DT B-NP O\\n',\n",
       " 'European NNP I-NP B-ORG\\n']"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('train.txt')\n",
    "f.readlines()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jc5Vnr69m0n8"
   },
   "source": [
    "## 3. 데이터 전처리하기\n",
    "- bi-LSTM 을 이용해서 개체명 인식 태깅을 하는 모델을 만들어보자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "yhqz9TG3m-2C"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "_UC2OXmql0CB"
   },
   "outputs": [],
   "source": [
    "# raw data 전처리\n",
    "train_set = 'train.txt'\n",
    "tagged_sentences = []\n",
    "sentence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "8RclqMspnI1g"
   },
   "outputs": [],
   "source": [
    "with open(train_set, 'r') as f:\n",
    "  for line in f.readlines():\n",
    "    if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == '\\n':\n",
    "      if len(sentence) > 0 :\n",
    "        tagged_sentences.append(sentence)\n",
    "        sentence = []\n",
    "      continue\n",
    "    splits = line.split(' ') \n",
    "    splits[-1] = splits[-1][:-1] # same as 're.sub(r'\\n', '', splits[-1])'\n",
    "    word = splits[0].lower()\n",
    "    sentence.append([word, splits[-1]]) # 단어와 개체명 태깅만 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlxD_UVHnJNA",
    "outputId": "cd9f9950-9cb6-425e-e0a3-cb4c84d88000"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14041"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagged_sentences[n][m] , n == 14041\n",
    "len(tagged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CSQvqQVWnJSw",
    "outputId": "4a772041-1606-4608-ea4d-78a36e508795"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['eu', 'B-ORG'],\n",
       " ['rejects', 'O'],\n",
       " ['german', 'B-MISC'],\n",
       " ['call', 'O'],\n",
       " ['to', 'O'],\n",
       " ['boycott', 'O'],\n",
       " ['british', 'B-MISC'],\n",
       " ['lamb', 'O'],\n",
       " ['.', 'O']]"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wm2-x7z5vKJW"
   },
   "source": [
    "### sentence, ner_tag분리\n",
    "- zip()함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "tQhzE8_ynJXy"
   },
   "outputs": [],
   "source": [
    "sentences,  ner_tags = [], []\n",
    "for tagged_sentence in tagged_sentences:\n",
    "  sentence, tag_info = zip(*tagged_sentence)\n",
    "  sentences.append(list(sentence))\n",
    "  ner_tags.append(list(tag_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zgp1KsNivwey",
    "outputId": "9e296349-44e5-4057-e648-5824fe1ddce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rabinovich', 'is', 'winding', 'up', 'his', 'term', 'as', 'ambassador', '.']\n",
      "['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[100])\n",
    "print(ner_tags[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SI_A9zYawJa5"
   },
   "source": [
    "### 14,041개의 문장 샘플 길이 확인\n",
    "- 전체 데이터의 길이 분포\n",
    "- map(func, iterator) : iterator 결과에 각각 func을 적용하여 반환값 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35MmSVqQwIwf",
    "outputId": "5aa14096-77ac-4df3-84e4-1e90449b063a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of samples : 113\n",
      "average length of samples : 14.501887\n"
     ]
    }
   ],
   "source": [
    "print('maximum length of samples : %d' % max(len(l) for l in sentences))\n",
    "print('average length of samples : %f' % (sum(map(len, sentences)) /len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "t2AL8q6xxd-X",
    "outputId": "03b3f585-5264-4316-bad5-02f0282e19c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'number of samples')"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(s) for s in sentences], bins = 50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWvo0hpo0BAU"
   },
   "source": [
    "- 케라스 토크나이저를 통해서 토큰화와 정수 인코딩 진행\n",
    "- 문장 데이터 안의 모든 단어를 사용하지 않고 높은 빈도수를 가진 상위 약 4000개 단어만 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTeDyA2P1FuD"
   },
   "source": [
    "### Keras Tokenizer\n",
    "- text corpus를 벡터화하는 class\n",
    "- fit_on_texts(sentences) : 내부 vocab을 sentence기반으로 업데이트 하는 함수\n",
    "- texts_to_sequences(texts) : texts안의 각 text를 정수 시퀀스 형태로 바꾸어주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WjkoB2IR1k1m",
    "outputId": "399db1f4-1828-46a8-c184-4847896b21fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Tokenizer in module keras_preprocessing.text:\n",
      "\n",
      "class Tokenizer(builtins.object)\n",
      " |  Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0, **kwargs)\n",
      " |  \n",
      " |  Text tokenization utility class.\n",
      " |  \n",
      " |  This class allows to vectorize a text corpus, by turning each\n",
      " |  text into either a sequence of integers (each integer being the index\n",
      " |  of a token in a dictionary) or into a vector where the coefficient\n",
      " |  for each token could be binary, based on word count, based on tf-idf...\n",
      " |  \n",
      " |  # Arguments\n",
      " |      num_words: the maximum number of words to keep, based\n",
      " |          on word frequency. Only the most common `num_words-1` words will\n",
      " |          be kept.\n",
      " |      filters: a string where each element is a character that will be\n",
      " |          filtered from the texts. The default is all punctuation, plus\n",
      " |          tabs and line breaks, minus the `'` character.\n",
      " |      lower: boolean. Whether to convert the texts to lowercase.\n",
      " |      split: str. Separator for word splitting.\n",
      " |      char_level: if True, every character will be treated as a token.\n",
      " |      oov_token: if given, it will be added to word_index and used to\n",
      " |          replace out-of-vocabulary words during text_to_sequence calls\n",
      " |  \n",
      " |  By default, all punctuation is removed, turning the texts into\n",
      " |  space-separated sequences of words\n",
      " |  (words maybe include the `'` character). These sequences are then\n",
      " |  split into lists of tokens. They will then be indexed or vectorized.\n",
      " |  \n",
      " |  `0` is a reserved index that won't be assigned to any word.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_on_sequences(self, sequences)\n",
      " |      Updates internal vocabulary based on a list of sequences.\n",
      " |      \n",
      " |      Required before using `sequences_to_matrix`\n",
      " |      (if `fit_on_texts` was never called).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequence.\n",
      " |              A \"sequence\" is a list of integer word indices.\n",
      " |  \n",
      " |  fit_on_texts(self, texts)\n",
      " |      Updates internal vocabulary based on a list of texts.\n",
      " |      \n",
      " |      In the case where texts contains lists,\n",
      " |      we assume each entry of the lists to be a token.\n",
      " |      \n",
      " |      Required before using `texts_to_sequences` or `texts_to_matrix`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: can be a list of strings,\n",
      " |              a generator of strings (for memory-efficiency),\n",
      " |              or a list of list of strings.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the tokenizer configuration as Python dictionary.\n",
      " |      The word count dictionaries used by the tokenizer get serialized\n",
      " |      into plain JSON, so that the configuration can be read by other\n",
      " |      projects.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Python dictionary with the tokenizer configuration.\n",
      " |  \n",
      " |  sequences_to_matrix(self, sequences, mode='binary')\n",
      " |      Converts a list of sequences into a Numpy matrix.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: list of sequences\n",
      " |              (a sequence is a list of integer word indices).\n",
      " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy matrix.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid `mode` argument,\n",
      " |              or if the Tokenizer requires to be fit to sample data.\n",
      " |  \n",
      " |  sequences_to_texts(self, sequences)\n",
      " |      Transforms each sequence into a list of text.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequences (list of integers).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of texts (strings)\n",
      " |  \n",
      " |  sequences_to_texts_generator(self, sequences)\n",
      " |      Transforms each sequence in `sequences` to a list of texts(strings).\n",
      " |      \n",
      " |      Each sequence has to a list of integers.\n",
      " |      In other words, sequences should be a list of sequences\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          sequences: A list of sequences.\n",
      " |      \n",
      " |      # Yields\n",
      " |          Yields individual texts.\n",
      " |  \n",
      " |  texts_to_matrix(self, texts, mode='binary')\n",
      " |      Convert a list of texts to a Numpy matrix.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: list of strings.\n",
      " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy matrix.\n",
      " |  \n",
      " |  texts_to_sequences(self, texts)\n",
      " |      Transforms each text in texts to a sequence of integers.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: A list of texts (strings).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of sequences.\n",
      " |  \n",
      " |  texts_to_sequences_generator(self, texts)\n",
      " |      Transforms each text in `texts` to a sequence of integers.\n",
      " |      \n",
      " |      Each item in texts can also be a list,\n",
      " |      in which case we assume each item of that list to be a token.\n",
      " |      \n",
      " |      Only top `num_words-1` most frequent words will be taken into account.\n",
      " |      Only words known by the tokenizer will be taken into account.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          texts: A list of texts (strings).\n",
      " |      \n",
      " |      # Yields\n",
      " |          Yields individual sequences.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the tokenizer configuration.\n",
      " |      To load a tokenizer from a JSON string, use\n",
      " |      `keras.preprocessing.text.tokenizer_from_json(json_string)`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A JSON string containing the tokenizer configuration.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "TQy_MEuwzHaV"
   },
   "outputs": [],
   "source": [
    "max_words = 4000\n",
    "\n",
    "# src : sentences -> trg : ner tags\n",
    "src_tokenizer = Tokenizer(num_words = max_words, oov_token='OOV')\n",
    "src_tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB7GOZfk0p-M",
    "outputId": "9064325f-6d44-4fc3-c58f-f8206f0f1f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 4000\n",
      "개체명 태깅 정보 집합의 크기 : 10\n"
     ]
    }
   ],
   "source": [
    "vocab_size = max_words\n",
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "dM9uCU7n3pQv"
   },
   "outputs": [],
   "source": [
    "# 정수 인코딩 수행\n",
    "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
    "Y_train = tar_tokenizer.texts_to_sequences(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJsMoYse4GG4",
    "outputId": "2ef6ccbe-0df7-41ba-bf2c-286e1590c011"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([989, 1, 205, 629, 7, 3939, 216, 1, 3], [4, 1, 7, 1, 1, 1, 7, 1, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "S7bwa9Nh4Glo"
   },
   "outputs": [],
   "source": [
    "# 현재 문장 데이터에 대해서는 일부 단어가 'OOV'로 대체된 상황이므로\n",
    "# 이를 확인하기 위해 다시 디코딩 작업 실시\n",
    "index_to_word = src_tokenizer.index_word\n",
    "index_to_ner = tar_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HovVMvmE4yu3",
    "outputId": "778b9f71-b3d1-4999-87a7-5c101c0834c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 문장 ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
      "빈도수가 낮은 단어가 OOV 처리된 문장 : ['eu', 'OOV', 'german', 'call', 'to', 'boycott', 'british', 'OOV', '.']\n"
     ]
    }
   ],
   "source": [
    "# 정수 인코딩 된 문장을 다시 디코딩 해보기\n",
    "decoded = []\n",
    "for idx in X_train[0]:\n",
    "  decoded.append(index_to_word[idx])\n",
    "\n",
    "print('기존 문장 {}'.format(sentences[0]))\n",
    "print('빈도수가 낮은 단어가 OOV 처리된 문장 : {}'.format(decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "MoaKwWHQ4zOX"
   },
   "outputs": [],
   "source": [
    "# 앞서 본 그래프에 따르면 대부분의 샘플 길이가 70 이내 이므로\n",
    "# X_train, Y_train 샘플들의 모든 길이를 임의오 70 정도로 맞추어 보기\n",
    "max_len = 70\n",
    "\n",
    "# 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움\n",
    "X_train = pad_sequences(X_train, padding = 'post', maxlen = max_len)\n",
    "Y_train = pad_sequences(Y_train, padding = 'post', maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "6sQ1Rmg84zeX"
   },
   "outputs": [],
   "source": [
    "# train : test  = 8 : 2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = .2, random_state = 777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "MlrxFJA3CBQI"
   },
   "outputs": [],
   "source": [
    "# 레이블에 해당하는 태깅 정보에 대해서 one-hot encoding 수행\n",
    "Y_train = to_categorical(Y_train, num_classes=tag_size)\n",
    "Y_test = to_categorical(Y_test, num_classes=tag_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tA4ZRL6k6jik",
    "outputId": "b1b27e89-7826-438c-d1a2-be7aab5e7f0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기 : (11232, 70)\n",
      "훈련 샘플 레이블의 크기 : (11232, 70, 10)\n",
      "테스트 샘플 문장의 크기 : (2809, 70)\n",
      "테스트 샘플 레이블의 크기 : (2809, 70, 10)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(Y_train.shape))\n",
    "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qiL7qpbv6sT1"
   },
   "source": [
    "## 4. 양방향 LSTM(Bi-directional LSTM)으로 개체명 인식기 만들기\n",
    "- Embedding layer 추가  \n",
    ": 각 데이터의 길이가 달라서 패딩을 하느라 숫자 0이 많아 졌으므로 숫자 0은 연산에서 제외시키는 옵션은 mask_zero = True 추가\n",
    "- Bidirectional LSTM layer 추가   \n",
    ": n-n 문제이므로 return_sequences = True임\n",
    "- TimeDistributed layer 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ka_bwTLt7eu8"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "z-Zr05tv6rFy"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "afjI6FAl-Suf"
   },
   "outputs": [],
   "source": [
    "#help(Embedding)\n",
    "#help(Bidirectional)\n",
    "#help(TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "E3Uh1dpq62S5"
   },
   "outputs": [],
   "source": [
    "# 모델 설계를 위한 도구 임포트\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "2nyQGbV562vh"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "orpLh5ks_6rm",
    "outputId": "9cf83047-a296-4227-f04a-67a64de2ab23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11232, 70), (11232, 70, 10), (2809, 70), (2809, 70, 10))"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape,  X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vq3jujd0621y",
    "outputId": "95fd630b-2fd0-4619-d87c-864ece4befc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "88/88 [==============================] - 40s 53ms/step - loss: 0.2559 - accuracy: 0.7941 - val_loss: 0.1240 - val_accuracy: 0.8335\n",
      "Epoch 2/8\n",
      "88/88 [==============================] - 3s 29ms/step - loss: 0.1134 - accuracy: 0.8432 - val_loss: 0.0738 - val_accuracy: 0.8908\n",
      "Epoch 3/8\n",
      "88/88 [==============================] - 2s 28ms/step - loss: 0.0687 - accuracy: 0.8996 - val_loss: 0.0545 - val_accuracy: 0.9217\n",
      "Epoch 4/8\n",
      "88/88 [==============================] - 2s 28ms/step - loss: 0.0484 - accuracy: 0.9318 - val_loss: 0.0404 - val_accuracy: 0.9441\n",
      "Epoch 5/8\n",
      "88/88 [==============================] - 3s 29ms/step - loss: 0.0363 - accuracy: 0.9493 - val_loss: 0.0352 - val_accuracy: 0.9510\n",
      "Epoch 6/8\n",
      "88/88 [==============================] - 3s 29ms/step - loss: 0.0292 - accuracy: 0.9584 - val_loss: 0.0335 - val_accuracy: 0.9537\n",
      "Epoch 7/8\n",
      "88/88 [==============================] - 2s 28ms/step - loss: 0.0256 - accuracy: 0.9643 - val_loss: 0.0318 - val_accuracy: 0.9547\n",
      "Epoch 8/8\n",
      "88/88 [==============================] - 2s 28ms/step - loss: 0.0215 - accuracy: 0.9693 - val_loss: 0.0313 - val_accuracy: 0.9572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe370118c10>"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=128, epochs=8,  validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjZa-Fdg625b",
    "outputId": "4b616764-34f7-40b3-bfb0-8cc1e954d122"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 1s 7ms/step - loss: 0.0313 - accuracy: 0.9572\n",
      "\n",
      " 테스트 정확도: 0.9572\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpqBe6pw628x",
    "outputId": "5127712a-2541-480b-81ac-bd1d79ded359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fe37dab6d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x7fe37dab6d40>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fe37dab6d40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x7fe37dab6d40>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "sarah            : B-PER   B-PER\n",
      "brady            : I-PER   I-PER\n",
      ",                : O       O\n",
      "whose            : O       O\n",
      "republican       : B-MISC  B-MISC\n",
      "husband          : O       O\n",
      "was              : O       O\n",
      "OOV              : O       O\n",
      "OOV              : O       O\n",
      "in               : O       O\n",
      "an               : O       O\n",
      "OOV              : O       O\n",
      "attempt          : O       O\n",
      "on               : O       O\n",
      "president        : O       O\n",
      "ronald           : B-PER   B-PER\n",
      "reagan           : I-PER   I-PER\n",
      ",                : O       O\n",
      "took             : O       O\n",
      "centre           : O       O\n",
      "stage            : O       O\n",
      "at               : O       O\n",
      "the              : O       O\n",
      "democratic       : B-MISC  B-MISC\n",
      "national         : I-MISC  I-MISC\n",
      "convention       : I-MISC  I-MISC\n",
      "on               : O       O\n",
      "monday           : O       O\n",
      "night            : O       O\n",
      "to               : O       O\n",
      "OOV              : O       O\n",
      "president        : O       O\n",
      "bill             : B-PER   B-PER\n",
      "clinton          : I-PER   I-PER\n",
      "'s               : O       O\n",
      "gun              : O       O\n",
      "control          : O       O\n",
      "efforts          : O       O\n",
      ".                : O       O\n"
     ]
    }
   ],
   "source": [
    "i = 10  # 확인하고 싶은 테스트용 샘플의 인덱스\n",
    "y_predicted = model.predict(np.array([X_test[i]]))\n",
    "y_predicted = np.argmax(y_predicted, axis = -1)\n",
    "true = np.argmax(Y_test[i], -1)\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
    "    if w != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t].upper(), index_to_ner[pred].upper()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WD4H_4cbDksB"
   },
   "source": [
    "- 해당 방법은 정확한 정확도 계산 방법은 아님\n",
    "- O가 태깅된 상황에서 예측 정확도가 수만은 O로 결정되고 있기 때문\n",
    "- F1-score를 도입하면 정확도를 좀 더 잘 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qI5xsGYnwuw_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLpmwA4awu0D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXGtw8pIwu3H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qATRXMLwu6f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhM61ivHwu96"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfhtLeTRwvA3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bP0-FaNOwvD_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bi-lstm_ner_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
