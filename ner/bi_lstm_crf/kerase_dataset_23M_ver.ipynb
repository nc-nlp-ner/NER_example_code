{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
      "  Cloning https://www.github.com/keras-team/keras-contrib.git to /private/var/folders/q9/pty21jc157l8w174dv7rhpr80000gn/T/pip-req-build-0__4vt6z\n",
      "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /Users/mac/opt/anaconda3/lib/python3.7/site-packages\n",
      "Requirement already satisfied: keras in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from keras-contrib==2.0.8) (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from keras->keras-contrib==2.0.8) (1.19.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
      "Requirement already satisfied: pyyaml in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from keras->keras-contrib==2.0.8) (5.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
      "Requirement already satisfied: h5py in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from keras->keras-contrib==2.0.8) (1.5.0)\n",
      "Building wheels for collected packages: keras-contrib\n",
      "  Building wheel for keras-contrib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101064 sha256=79bc4951afd681297e097d6584324ac98308a2617639d80b602fb4c8974c4d75\n",
      "  Stored in directory: /private/var/folders/q9/pty21jc157l8w174dv7rhpr80000gn/T/pip-ephem-wheel-cache-vl2ucw1j/wheels/bb/1f/f2/b57495012683b6b20bbae94a3915ec79753111452d79886abc\n",
      "Successfully built keras-contrib\n",
      "Requirement already satisfied: seqeval in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from seqeval) (1.19.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from seqeval) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mac/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "# install keras-contrib for using CRF \n",
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
    "# for F1-score measurement callback class\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import Callback\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras.models import load_model\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras_contrib.metrics import crf_viterbi_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing\n",
    "### Using Data list\n",
    "1. MSRA (14M)\n",
    "2. People's Daily(8M)\n",
    "3. Weibo (605KB)\n",
    "\n",
    "### Data information\n",
    "- word&tag split : \\t(tab)\n",
    "- sentences split : \\n(new line)\n",
    "- ne tag : LOC, ORG, PER, GPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = '../data/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_data_preprocessing(file_name):\n",
    "    tagged_sentences = []\n",
    "    sentence = []\n",
    "    with open(file_name,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if len(line) == 0 or line[0] == '\\n':\n",
    "                if len(sentence) > 0:\n",
    "                    tagged_sentences.append(sentence)\n",
    "                    sentence = []\n",
    "                continue\n",
    "            if line =='0\\t\\n':\n",
    "                continue\n",
    "            word, ner_tag = line.strip().split('\\t') \n",
    "            sentence.append([word, ner_tag])\n",
    "    return tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = raw_data_preprocessing(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate sentence, ner_tag\n",
    "def separate_sent_tag(tagged_sentences):\n",
    "    sentences,  ner_tags = [], []\n",
    "    for tagged_sentence in tagged_sentences:\n",
    "        sentence, tag_info = zip(*tagged_sentence)\n",
    "        sentences.append(list(sentence))\n",
    "        ner_tags.append(list(tag_info))\n",
    "    return sentences, ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78150 78150\n"
     ]
    }
   ],
   "source": [
    "sentences, ner_tags = separate_sent_tag(sents)\n",
    "print(len(sentences), len(ner_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有家洗衣机生产企业，突然发现一些地区和城市的报纸上先后出现了同一篇文章，针对性极强，消费者看过这篇文章，可以得出这样的印象，低于某价格的洗衣机靠不住。"
     ]
    }
   ],
   "source": [
    "for ch in sentences[70000]:\n",
    "    print(ch,end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the dataset to train/test set\n",
    "- the total dataset size is in units of 10 thousand, so split it in a 8:2 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, test_sentences, ner_tags, test_ner_tags = train_test_split(sentences, ner_tags, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set : 62520 62520\n",
      "test set:  15630 15630\n"
     ]
    }
   ],
   "source": [
    "print(\"train set :\", len(sentences), len(ner_tags))\n",
    "print(\"test set: \", len(test_sentences), len(test_ner_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of samples : 2427\n",
      "mean length of samples : 47.993586\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the whole train data\n",
    "print('maximum length of samples : %d' % max(len(l) for l in sentences))\n",
    "print('mean length of samples : %f' % (sum(map(len, sentences))/len(sentences)))\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of samples : 746\n",
      "mean length of samples : 48.300320\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the whole data\n",
    "print('maximum length of samples : %d' % max(len(l) for l in test_sentences))\n",
    "print('mean length of samples : %f' % (sum(map(len, test_sentences))/len(test_sentences)))\n",
    "plt.hist([len(s) for s in test_sentences], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of word set : 5341\n",
      "size of named entity tagging information set : 10\n",
      "index of word OOV: 1\n"
     ]
    }
   ],
   "source": [
    "# integer encoding using keras tokenizer\n",
    "src_tokenizer = Tokenizer(oov_token = 'OOV')\n",
    "src_tokenizer.fit_on_texts(sentences + test_sentences)\n",
    "tar_tokenizer = Tokenizer(lower=False)\n",
    "tar_tokenizer.fit_on_texts(ner_tags + test_ner_tags)\n",
    "\n",
    "vocab_size = len(src_tokenizer.word_index) + 1\n",
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "print('size of word set : {}'.format(vocab_size))\n",
    "print('size of named entity tagging information set : {}'.format(tag_size))\n",
    "print('index of word OOV: {}'.format(src_tokenizer.word_index['OOV']))\n",
    "\n",
    "# perform integer encoding\n",
    "X_data = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_data = tar_tokenizer.texts_to_sequences(ner_tags)\n",
    "# perform integer encoding\n",
    "X_test = src_tokenizer.texts_to_sequences(test_sentences)\n",
    "y_test = tar_tokenizer.texts_to_sequences(test_ner_tags)\n",
    "\n",
    "# create the 'index to word\n",
    "word_to_index = src_tokenizer.word_index\n",
    "index_to_word = src_tokenizer.index_word\n",
    "ner_to_index = tar_tokenizer.word_index\n",
    "index_to_ner = tar_tokenizer.index_word\n",
    "index_to_ner[0] = 'PAD' \n",
    "\n",
    "# padding\n",
    "max_len = 200\n",
    "X_data = pad_sequences(X_data, padding='post', maxlen=max_len)\n",
    "y_data = pad_sequences(y_data, padding='post', maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=max_len)\n",
    "y_test = pad_sequences(y_test, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train sample's sentence : (62520, 200)\n",
      "size of train sample's label: (62520, 200, 10)\n",
      "size of test sample's sentence : (15630, 200)\n",
      "size of test sample's label: (15630, 200, 10)\n"
     ]
    }
   ],
   "source": [
    "# split the data 8 : 2 (train : test)\n",
    "X_train, y_train = X_data, y_data\n",
    "\n",
    "# one-hot encoding \n",
    "y_train = to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test, num_classes=tag_size)\n",
    "\n",
    "# cheack the dimension\n",
    "print('size of train sample\\'s sentence : {}'.format(X_train.shape))\n",
    "print('size of train sample\\'s label: {}'.format(y_train.shape))\n",
    "print('size of test sample\\'s sentence : {}'.format(X_test.shape))\n",
    "print('size of test sample\\'s label: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train the model\n",
    "\n",
    "### Callback class for measure the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1score(Callback):\n",
    "    def __init__(self, value = 0.0, use_char=True):\n",
    "        super(F1score, self).__init__()\n",
    "        self.value = value\n",
    "        self.use_char = use_char\n",
    "\n",
    "    def sequences_to_tags(self, sequences): # predicted value to tagging information using index_to_ner.\n",
    "      result = []\n",
    "      for sequence in sequences: \n",
    "          tag = []\n",
    "          for pred in sequence: \n",
    "              pred_index = np.argmax(pred) \n",
    "              tag.append(index_to_ner[pred_index].replace(\"PAD\", \"O\")) # 'PAD' -> 'O'\n",
    "          result.append(tag)\n",
    "      return result\n",
    "\n",
    "    # executed function when end the epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "      # using char Embedding\n",
    "      if self.use_char:\n",
    "        X_test = self.validation_data[0]\n",
    "        X_char_test = self.validation_data[1]\n",
    "        y_test = self.validation_data[2]\n",
    "        y_predicted = self.model.predict([X_test, X_char_test])\n",
    "\n",
    "      else:\n",
    "        X_test = self.validation_data[0]\n",
    "        y_test = self.validation_data[1]\n",
    "        y_predicted = self.model.predict([X_test])\n",
    "\n",
    "      pred_tags = self.sequences_to_tags(y_predicted)\n",
    "      test_tags = self.sequences_to_tags(y_test)\n",
    "\n",
    "      score = f1_score(pred_tags, test_tags)\n",
    "      print(' - f1: {:04.2f}'.format(score * 100))\n",
    "      print(classification_report(test_tags, pred_tags))\n",
    "\n",
    "      # best F1-score \n",
    "      if score > self.value:\n",
    "        print('f1_score improved from %f to %f, saving model to best_model.h5'%(self.value, score))\n",
    "        self.model.save('best_model.h5')\n",
    "        self.value = score\n",
    "      else:\n",
    "        print('f1_score did not improve from %f'%(self.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM + CRF based NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mac/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mac/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mac/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mac/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/mac/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(50, activation=\"relu\")))\n",
    "crf = CRF(tag_size)\n",
    "model.add(crf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56268 samples, validate on 6252 samples\n",
      "Epoch 1/50\n",
      "56268/56268 [==============================] - 528s 9ms/step - loss: 10.5064 - crf_viterbi_accuracy: 0.9785 - val_loss: 10.4527 - val_crf_viterbi_accuracy: 0.9800\n",
      " - f1: 83.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/opt/anaconda3/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.00      0.00      0.00        24\n",
      "         LOC       0.88      0.83      0.85      4733\n",
      "         ORG       0.82      0.75      0.78      2740\n",
      "         PER       0.91      0.85      0.88      2558\n",
      "\n",
      "   micro avg       0.87      0.81      0.84     10055\n",
      "   macro avg       0.65      0.61      0.63     10055\n",
      "weighted avg       0.87      0.81      0.84     10055\n",
      "\n",
      "f1_score improved from 0.000000 to 0.838404, saving model to best_model.h5\n",
      "Epoch 2/50\n",
      "56268/56268 [==============================] - 482s 9ms/step - loss: 10.4975 - crf_viterbi_accuracy: 0.9829 - val_loss: 10.4479 - val_crf_viterbi_accuracy: 0.9829\n",
      " - f1: 86.33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       1.00      0.04      0.08        24\n",
      "         LOC       0.90      0.86      0.88      4733\n",
      "         ORG       0.82      0.80      0.81      2740\n",
      "         PER       0.92      0.88      0.90      2558\n",
      "\n",
      "   micro avg       0.88      0.85      0.86     10055\n",
      "   macro avg       0.91      0.65      0.67     10055\n",
      "weighted avg       0.88      0.85      0.86     10055\n",
      "\n",
      "f1_score improved from 0.838404 to 0.863312, saving model to best_model.h5\n",
      "Epoch 3/50\n",
      "56268/56268 [==============================] - 480s 9ms/step - loss: 10.4923 - crf_viterbi_accuracy: 0.9861 - val_loss: 10.4453 - val_crf_viterbi_accuracy: 0.9838\n",
      " - f1: 87.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.50      0.17      0.25        24\n",
      "         LOC       0.91      0.88      0.89      4733\n",
      "         ORG       0.84      0.82      0.83      2740\n",
      "         PER       0.92      0.89      0.90      2558\n",
      "\n",
      "   micro avg       0.89      0.86      0.88     10055\n",
      "   macro avg       0.79      0.69      0.72     10055\n",
      "weighted avg       0.89      0.86      0.88     10055\n",
      "\n",
      "f1_score improved from 0.863312 to 0.876830, saving model to best_model.h5\n",
      "Epoch 4/50\n",
      "56268/56268 [==============================] - 508s 9ms/step - loss: 10.4886 - crf_viterbi_accuracy: 0.9887 - val_loss: 10.4435 - val_crf_viterbi_accuracy: 0.9865\n",
      " - f1: 89.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.80      0.17      0.28        24\n",
      "         LOC       0.91      0.90      0.91      4733\n",
      "         ORG       0.88      0.82      0.85      2740\n",
      "         PER       0.93      0.91      0.92      2558\n",
      "\n",
      "   micro avg       0.91      0.88      0.89     10055\n",
      "   macro avg       0.88      0.70      0.74     10055\n",
      "weighted avg       0.91      0.88      0.89     10055\n",
      "\n",
      "f1_score improved from 0.876830 to 0.893437, saving model to best_model.h5\n",
      "Epoch 5/50\n",
      "56268/56268 [==============================] - 493s 9ms/step - loss: 10.4856 - crf_viterbi_accuracy: 0.9911 - val_loss: 10.4438 - val_crf_viterbi_accuracy: 0.9866\n",
      " - f1: 89.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.36      0.21      0.26        24\n",
      "         LOC       0.92      0.89      0.91      4733\n",
      "         ORG       0.88      0.84      0.86      2740\n",
      "         PER       0.94      0.89      0.91      2558\n",
      "\n",
      "   micro avg       0.91      0.88      0.89     10055\n",
      "   macro avg       0.77      0.71      0.74     10055\n",
      "weighted avg       0.91      0.88      0.89     10055\n",
      "\n",
      "f1_score improved from 0.893437 to 0.894552, saving model to best_model.h5\n",
      "Epoch 6/50\n",
      "56268/56268 [==============================] - 487s 9ms/step - loss: 10.4834 - crf_viterbi_accuracy: 0.9928 - val_loss: 10.4426 - val_crf_viterbi_accuracy: 0.9879\n",
      " - f1: 90.53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.75      0.25      0.38        24\n",
      "         LOC       0.90      0.94      0.92      4733\n",
      "         ORG       0.90      0.83      0.86      2740\n",
      "         PER       0.94      0.91      0.93      2558\n",
      "\n",
      "   micro avg       0.91      0.90      0.91     10055\n",
      "   macro avg       0.87      0.73      0.77     10055\n",
      "weighted avg       0.91      0.90      0.90     10055\n",
      "\n",
      "f1_score improved from 0.894552 to 0.905317, saving model to best_model.h5\n",
      "Epoch 7/50\n",
      "56268/56268 [==============================] - 507s 9ms/step - loss: 10.4817 - crf_viterbi_accuracy: 0.9943 - val_loss: 10.4422 - val_crf_viterbi_accuracy: 0.9889\n",
      " - f1: 91.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.83      0.21      0.33        24\n",
      "         LOC       0.93      0.93      0.93      4733\n",
      "         ORG       0.92      0.85      0.89      2740\n",
      "         PER       0.95      0.91      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.90      0.92     10055\n",
      "   macro avg       0.91      0.72      0.77     10055\n",
      "weighted avg       0.93      0.90      0.92     10055\n",
      "\n",
      "f1_score improved from 0.905317 to 0.916452, saving model to best_model.h5\n",
      "Epoch 8/50\n",
      "56268/56268 [==============================] - 507s 9ms/step - loss: 10.4804 - crf_viterbi_accuracy: 0.9956 - val_loss: 10.4436 - val_crf_viterbi_accuracy: 0.9891\n",
      " - f1: 91.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.67      0.25      0.36        24\n",
      "         LOC       0.93      0.93      0.93      4733\n",
      "         ORG       0.91      0.86      0.88      2740\n",
      "         PER       0.93      0.92      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.91      0.92     10055\n",
      "   macro avg       0.86      0.74      0.78     10055\n",
      "weighted avg       0.93      0.91      0.92     10055\n",
      "\n",
      "f1_score improved from 0.916452 to 0.917093, saving model to best_model.h5\n",
      "Epoch 9/50\n",
      "56268/56268 [==============================] - 509s 9ms/step - loss: 10.4794 - crf_viterbi_accuracy: 0.9964 - val_loss: 10.4436 - val_crf_viterbi_accuracy: 0.9897\n",
      " - f1: 92.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.62      0.21      0.31        24\n",
      "         LOC       0.94      0.93      0.94      4733\n",
      "         ORG       0.89      0.89      0.89      2740\n",
      "         PER       0.94      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.92      0.92     10055\n",
      "   macro avg       0.85      0.74      0.77     10055\n",
      "weighted avg       0.93      0.92      0.92     10055\n",
      "\n",
      "f1_score improved from 0.917093 to 0.922476, saving model to best_model.h5\n",
      "Epoch 10/50\n",
      "56268/56268 [==============================] - 508s 9ms/step - loss: 10.4788 - crf_viterbi_accuracy: 0.9970 - val_loss: 10.4446 - val_crf_viterbi_accuracy: 0.9896\n",
      " - f1: 91.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.23      0.29      0.25        24\n",
      "         LOC       0.94      0.93      0.94      4733\n",
      "         ORG       0.92      0.87      0.89      2740\n",
      "         PER       0.92      0.93      0.92      2558\n",
      "\n",
      "   micro avg       0.93      0.91      0.92     10055\n",
      "   macro avg       0.75      0.76      0.75     10055\n",
      "weighted avg       0.93      0.91      0.92     10055\n",
      "\n",
      "f1_score did not improve from 0.922476\n",
      "Epoch 11/50\n",
      "56268/56268 [==============================] - 511s 9ms/step - loss: 10.4782 - crf_viterbi_accuracy: 0.9977 - val_loss: 10.4467 - val_crf_viterbi_accuracy: 0.9897\n",
      " - f1: 92.02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.86      0.25      0.39        24\n",
      "         LOC       0.94      0.93      0.93      4733\n",
      "         ORG       0.91      0.87      0.89      2740\n",
      "         PER       0.93      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.91      0.92     10055\n",
      "   macro avg       0.91      0.74      0.79     10055\n",
      "weighted avg       0.93      0.91      0.92     10055\n",
      "\n",
      "f1_score did not improve from 0.922476\n",
      "Epoch 12/50\n",
      "56268/56268 [==============================] - 515s 9ms/step - loss: 10.4780 - crf_viterbi_accuracy: 0.9977 - val_loss: 10.4469 - val_crf_viterbi_accuracy: 0.9898\n",
      " - f1: 92.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.67      0.25      0.36        24\n",
      "         LOC       0.94      0.93      0.94      4733\n",
      "         ORG       0.92      0.87      0.89      2740\n",
      "         PER       0.95      0.92      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.91      0.92     10055\n",
      "   macro avg       0.87      0.74      0.78     10055\n",
      "weighted avg       0.93      0.91      0.92     10055\n",
      "\n",
      "f1_score improved from 0.922476 to 0.923387, saving model to best_model.h5\n",
      "Epoch 13/50\n",
      "56268/56268 [==============================] - 510s 9ms/step - loss: 10.4777 - crf_viterbi_accuracy: 0.9981 - val_loss: 10.4474 - val_crf_viterbi_accuracy: 0.9901\n",
      " - f1: 92.37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.58      0.29      0.39        24\n",
      "         LOC       0.95      0.93      0.94      4733\n",
      "         ORG       0.90      0.89      0.90      2740\n",
      "         PER       0.92      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.92      0.92     10055\n",
      "   macro avg       0.84      0.76      0.79     10055\n",
      "weighted avg       0.93      0.92      0.92     10055\n",
      "\n",
      "f1_score improved from 0.923387 to 0.923661, saving model to best_model.h5\n",
      "Epoch 14/50\n",
      "56268/56268 [==============================] - 515s 9ms/step - loss: 10.4775 - crf_viterbi_accuracy: 0.9983 - val_loss: 10.4479 - val_crf_viterbi_accuracy: 0.9907\n",
      " - f1: 92.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.40      0.25      0.31        24\n",
      "         LOC       0.94      0.94      0.94      4733\n",
      "         ORG       0.92      0.89      0.90      2740\n",
      "         PER       0.95      0.93      0.94      2558\n",
      "\n",
      "   micro avg       0.93      0.92      0.93     10055\n",
      "   macro avg       0.80      0.75      0.77     10055\n",
      "weighted avg       0.93      0.92      0.93     10055\n",
      "\n",
      "f1_score improved from 0.923661 to 0.928457, saving model to best_model.h5\n",
      "Epoch 15/50\n",
      "56268/56268 [==============================] - 514s 9ms/step - loss: 10.4773 - crf_viterbi_accuracy: 0.9985 - val_loss: 10.4487 - val_crf_viterbi_accuracy: 0.9899\n",
      " - f1: 92.26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.50      0.25      0.33        24\n",
      "         LOC       0.93      0.94      0.93      4733\n",
      "         ORG       0.93      0.86      0.89      2740\n",
      "         PER       0.95      0.92      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.91      0.92     10055\n",
      "   macro avg       0.83      0.74      0.77     10055\n",
      "weighted avg       0.93      0.91      0.92     10055\n",
      "\n",
      "f1_score did not improve from 0.928457\n",
      "Epoch 16/50\n",
      "56268/56268 [==============================] - 517s 9ms/step - loss: 10.4772 - crf_viterbi_accuracy: 0.9986 - val_loss: 10.4493 - val_crf_viterbi_accuracy: 0.9902\n",
      " - f1: 92.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.80      0.33      0.47        24\n",
      "         LOC       0.94      0.94      0.94      4733\n",
      "         ORG       0.90      0.90      0.90      2740\n",
      "         PER       0.94      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.92      0.93     10055\n",
      "   macro avg       0.90      0.78      0.81     10055\n",
      "weighted avg       0.93      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.928457\n",
      "Epoch 17/50\n",
      "56268/56268 [==============================] - 499s 9ms/step - loss: 10.4772 - crf_viterbi_accuracy: 0.9988 - val_loss: 10.4504 - val_crf_viterbi_accuracy: 0.9903\n",
      " - f1: 92.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.62      0.21      0.31        24\n",
      "         LOC       0.94      0.94      0.94      4733\n",
      "         ORG       0.91      0.89      0.90      2740\n",
      "         PER       0.94      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.92      0.93     10055\n",
      "   macro avg       0.85      0.74      0.77     10055\n",
      "weighted avg       0.93      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.928457\n",
      "Epoch 18/50\n",
      "56268/56268 [==============================] - 499s 9ms/step - loss: 10.4770 - crf_viterbi_accuracy: 0.9990 - val_loss: 10.4500 - val_crf_viterbi_accuracy: 0.9904\n",
      " - f1: 92.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.46      0.25      0.32        24\n",
      "         LOC       0.94      0.94      0.94      4733\n",
      "         ORG       0.91      0.90      0.90      2740\n",
      "         PER       0.95      0.92      0.94      2558\n",
      "\n",
      "   micro avg       0.93      0.92      0.93     10055\n",
      "   macro avg       0.81      0.75      0.78     10055\n",
      "weighted avg       0.93      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.928457\n",
      "Epoch 19/50\n",
      "56268/56268 [==============================] - 494s 9ms/step - loss: 10.4770 - crf_viterbi_accuracy: 0.9990 - val_loss: 10.4504 - val_crf_viterbi_accuracy: 0.9902\n",
      " - f1: 92.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.55      0.25      0.34        24\n",
      "         LOC       0.94      0.94      0.94      4733\n",
      "         ORG       0.91      0.89      0.90      2740\n",
      "         PER       0.94      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.92      0.93     10055\n",
      "   macro avg       0.84      0.75      0.78     10055\n",
      "weighted avg       0.93      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.928457\n",
      "Epoch 20/50\n",
      "56268/56268 [==============================] - 495s 9ms/step - loss: 10.4770 - crf_viterbi_accuracy: 0.9989 - val_loss: 10.4506 - val_crf_viterbi_accuracy: 0.9904\n",
      " - f1: 92.54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.71      0.21      0.32        24\n",
      "         LOC       0.94      0.94      0.94      4733\n",
      "         ORG       0.92      0.89      0.90      2740\n",
      "         PER       0.93      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.92      0.93     10055\n",
      "   macro avg       0.88      0.74      0.77     10055\n",
      "weighted avg       0.93      0.92      0.92     10055\n",
      "\n",
      "f1_score did not improve from 0.928457\n",
      "Epoch 21/50\n",
      "56268/56268 [==============================] - 495s 9ms/step - loss: 10.4769 - crf_viterbi_accuracy: 0.9991 - val_loss: 10.4510 - val_crf_viterbi_accuracy: 0.9906\n",
      " - f1: 92.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.58      0.29      0.39        24\n",
      "         LOC       0.95      0.94      0.94      4733\n",
      "         ORG       0.92      0.89      0.91      2740\n",
      "         PER       0.95      0.92      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.85      0.76      0.79     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score improved from 0.928457 to 0.929934, saving model to best_model.h5\n",
      "Epoch 22/50\n",
      "56268/56268 [==============================] - 495s 9ms/step - loss: 10.4769 - crf_viterbi_accuracy: 0.9990 - val_loss: 10.4514 - val_crf_viterbi_accuracy: 0.9900\n",
      " - f1: 92.51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.46      0.25      0.32        24\n",
      "         LOC       0.96      0.92      0.94      4733\n",
      "         ORG       0.89      0.91      0.90      2740\n",
      "         PER       0.94      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.92      0.93     10055\n",
      "   macro avg       0.81      0.75      0.77     10055\n",
      "weighted avg       0.93      0.92      0.92     10055\n",
      "\n",
      "f1_score did not improve from 0.929934\n",
      "Epoch 23/50\n",
      "56268/56268 [==============================] - 498s 9ms/step - loss: 10.4769 - crf_viterbi_accuracy: 0.9991 - val_loss: 10.4511 - val_crf_viterbi_accuracy: 0.9907\n",
      " - f1: 92.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.60      0.25      0.35        24\n",
      "         LOC       0.95      0.93      0.94      4733\n",
      "         ORG       0.92      0.90      0.91      2740\n",
      "         PER       0.93      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.85      0.75      0.78     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.929934\n",
      "Epoch 24/50\n",
      "56268/56268 [==============================] - 496s 9ms/step - loss: 10.4767 - crf_viterbi_accuracy: 0.9993 - val_loss: 10.4520 - val_crf_viterbi_accuracy: 0.9900\n",
      " - f1: 92.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.46      0.25      0.32        24\n",
      "         LOC       0.95      0.93      0.94      4733\n",
      "         ORG       0.92      0.89      0.91      2740\n",
      "         PER       0.93      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.82      0.75      0.78     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.929934\n",
      "Epoch 25/50\n",
      "56268/56268 [==============================] - 495s 9ms/step - loss: 10.4769 - crf_viterbi_accuracy: 0.9991 - val_loss: 10.4509 - val_crf_viterbi_accuracy: 0.9905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - f1: 92.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.28      0.21      0.24        24\n",
      "         LOC       0.94      0.94      0.94      4733\n",
      "         ORG       0.92      0.90      0.91      2740\n",
      "         PER       0.94      0.92      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.92      0.93     10055\n",
      "   macro avg       0.77      0.74      0.75     10055\n",
      "weighted avg       0.93      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.929934\n",
      "Epoch 26/50\n",
      "56268/56268 [==============================] - 496s 9ms/step - loss: 10.4767 - crf_viterbi_accuracy: 0.9992 - val_loss: 10.4523 - val_crf_viterbi_accuracy: 0.9905\n",
      " - f1: 92.76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.67      0.17      0.27        24\n",
      "         LOC       0.94      0.94      0.94      4733\n",
      "         ORG       0.93      0.89      0.91      2740\n",
      "         PER       0.94      0.92      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.92      0.93     10055\n",
      "   macro avg       0.87      0.73      0.76     10055\n",
      "weighted avg       0.93      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.929934\n",
      "Epoch 27/50\n",
      "56268/56268 [==============================] - 496s 9ms/step - loss: 10.4767 - crf_viterbi_accuracy: 0.9992 - val_loss: 10.4523 - val_crf_viterbi_accuracy: 0.9911\n",
      " - f1: 93.11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.80      0.17      0.28        24\n",
      "         LOC       0.94      0.94      0.94      4733\n",
      "         ORG       0.91      0.90      0.91      2740\n",
      "         PER       0.95      0.91      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.90      0.73      0.77     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score improved from 0.929934 to 0.931116, saving model to best_model.h5\n",
      "Epoch 28/50\n",
      "56268/56268 [==============================] - 489s 9ms/step - loss: 10.4767 - crf_viterbi_accuracy: 0.9992 - val_loss: 10.4517 - val_crf_viterbi_accuracy: 0.9906\n",
      " - f1: 93.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.71      0.21      0.32        24\n",
      "         LOC       0.95      0.94      0.95      4733\n",
      "         ORG       0.92      0.90      0.91      2740\n",
      "         PER       0.94      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.88      0.74      0.78     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.931116\n",
      "Epoch 29/50\n",
      "56268/56268 [==============================] - 492s 9ms/step - loss: 10.4767 - crf_viterbi_accuracy: 0.9992 - val_loss: 10.4511 - val_crf_viterbi_accuracy: 0.9907\n",
      " - f1: 92.92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.62      0.33      0.43        24\n",
      "         LOC       0.94      0.95      0.94      4733\n",
      "         ORG       0.92      0.90      0.91      2740\n",
      "         PER       0.93      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10055\n",
      "   macro avg       0.85      0.78      0.80     10055\n",
      "weighted avg       0.93      0.93      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.931116\n",
      "Epoch 30/50\n",
      "56268/56268 [==============================] - 489s 9ms/step - loss: 10.4768 - crf_viterbi_accuracy: 0.9992 - val_loss: 10.4514 - val_crf_viterbi_accuracy: 0.9912\n",
      " - f1: 93.09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.55      0.25      0.34        24\n",
      "         LOC       0.95      0.94      0.94      4733\n",
      "         ORG       0.92      0.90      0.91      2740\n",
      "         PER       0.94      0.92      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.84      0.75      0.78     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.931116\n",
      "Epoch 31/50\n",
      "56268/56268 [==============================] - 491s 9ms/step - loss: 10.4767 - crf_viterbi_accuracy: 0.9993 - val_loss: 10.4519 - val_crf_viterbi_accuracy: 0.9909\n",
      " - f1: 93.17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.40      0.17      0.24        24\n",
      "         LOC       0.95      0.94      0.95      4733\n",
      "         ORG       0.92      0.90      0.91      2740\n",
      "         PER       0.94      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.93      0.93     10055\n",
      "   macro avg       0.80      0.73      0.76     10055\n",
      "weighted avg       0.94      0.93      0.93     10055\n",
      "\n",
      "f1_score improved from 0.931116 to 0.931692, saving model to best_model.h5\n",
      "Epoch 32/50\n",
      "56268/56268 [==============================] - 492s 9ms/step - loss: 10.4765 - crf_viterbi_accuracy: 0.9996 - val_loss: 10.4527 - val_crf_viterbi_accuracy: 0.9913\n",
      " - f1: 93.31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.35      0.25      0.29        24\n",
      "         LOC       0.95      0.94      0.94      4733\n",
      "         ORG       0.93      0.90      0.91      2740\n",
      "         PER       0.95      0.93      0.94      2558\n",
      "\n",
      "   micro avg       0.94      0.93      0.93     10055\n",
      "   macro avg       0.79      0.76      0.77     10055\n",
      "weighted avg       0.94      0.93      0.93     10055\n",
      "\n",
      "f1_score improved from 0.931692 to 0.933140, saving model to best_model.h5\n",
      "Epoch 33/50\n",
      "56268/56268 [==============================] - 490s 9ms/step - loss: 10.4767 - crf_viterbi_accuracy: 0.9993 - val_loss: 10.4534 - val_crf_viterbi_accuracy: 0.9909\n",
      " - f1: 93.13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.86      0.25      0.39        24\n",
      "         LOC       0.94      0.95      0.94      4733\n",
      "         ORG       0.93      0.90      0.91      2740\n",
      "         PER       0.95      0.92      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.92      0.75      0.79     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.933140\n",
      "Epoch 34/50\n",
      "56268/56268 [==============================] - 492s 9ms/step - loss: 10.4768 - crf_viterbi_accuracy: 0.9992 - val_loss: 10.4540 - val_crf_viterbi_accuracy: 0.9912\n",
      " - f1: 93.36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.86      0.25      0.39        24\n",
      "         LOC       0.95      0.94      0.94      4733\n",
      "         ORG       0.93      0.90      0.91      2740\n",
      "         PER       0.96      0.92      0.94      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.92      0.75      0.80     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score improved from 0.933140 to 0.933642, saving model to best_model.h5\n",
      "Epoch 35/50\n",
      "56268/56268 [==============================] - 501s 9ms/step - loss: 10.4765 - crf_viterbi_accuracy: 0.9996 - val_loss: 10.4526 - val_crf_viterbi_accuracy: 0.9912\n",
      " - f1: 93.38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.43      0.25      0.32        24\n",
      "         LOC       0.95      0.95      0.95      4733\n",
      "         ORG       0.92      0.91      0.92      2740\n",
      "         PER       0.94      0.93      0.94      2558\n",
      "\n",
      "   micro avg       0.94      0.93      0.93     10055\n",
      "   macro avg       0.81      0.76      0.78     10055\n",
      "weighted avg       0.94      0.93      0.93     10055\n",
      "\n",
      "f1_score improved from 0.933642 to 0.933813, saving model to best_model.h5\n",
      "Epoch 36/50\n",
      "56268/56268 [==============================] - 500s 9ms/step - loss: 10.4766 - crf_viterbi_accuracy: 0.9994 - val_loss: 10.4543 - val_crf_viterbi_accuracy: 0.9908\n",
      " - f1: 93.08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.67      0.17      0.27        24\n",
      "         LOC       0.94      0.95      0.94      4733\n",
      "         ORG       0.93      0.89      0.91      2740\n",
      "         PER       0.95      0.92      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.87      0.73      0.76     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.933813\n",
      "Epoch 37/50\n",
      "56268/56268 [==============================] - 498s 9ms/step - loss: 10.4766 - crf_viterbi_accuracy: 0.9994 - val_loss: 10.4543 - val_crf_viterbi_accuracy: 0.9909\n",
      " - f1: 93.07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.50      0.17      0.25        24\n",
      "         LOC       0.94      0.95      0.94      4733\n",
      "         ORG       0.92      0.90      0.91      2740\n",
      "         PER       0.95      0.92      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.83      0.73      0.76     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.933813\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56268/56268 [==============================] - 498s 9ms/step - loss: 10.4766 - crf_viterbi_accuracy: 0.9994 - val_loss: 10.4543 - val_crf_viterbi_accuracy: 0.9910\n",
      " - f1: 92.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.37      0.29      0.33        24\n",
      "         LOC       0.94      0.94      0.94      4733\n",
      "         ORG       0.92      0.91      0.92      2740\n",
      "         PER       0.93      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10055\n",
      "   macro avg       0.79      0.77      0.78     10055\n",
      "weighted avg       0.93      0.93      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.933813\n",
      "Epoch 39/50\n",
      "56268/56268 [==============================] - 499s 9ms/step - loss: 10.4765 - crf_viterbi_accuracy: 0.9995 - val_loss: 10.4559 - val_crf_viterbi_accuracy: 0.9914\n",
      " - f1: 93.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.56      0.21      0.30        24\n",
      "         LOC       0.96      0.93      0.94      4733\n",
      "         ORG       0.93      0.91      0.92      2740\n",
      "         PER       0.95      0.92      0.94      2558\n",
      "\n",
      "   micro avg       0.95      0.92      0.93     10055\n",
      "   macro avg       0.85      0.74      0.77     10055\n",
      "weighted avg       0.95      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.933813\n",
      "Epoch 40/50\n",
      "56268/56268 [==============================] - 499s 9ms/step - loss: 10.4766 - crf_viterbi_accuracy: 0.9995 - val_loss: 10.4554 - val_crf_viterbi_accuracy: 0.9909\n",
      " - f1: 92.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.56      0.21      0.30        24\n",
      "         LOC       0.94      0.94      0.94      4733\n",
      "         ORG       0.92      0.90      0.91      2740\n",
      "         PER       0.95      0.92      0.94      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.84      0.74      0.77     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.933813\n",
      "Epoch 41/50\n",
      "56268/56268 [==============================] - 511s 9ms/step - loss: 10.4765 - crf_viterbi_accuracy: 0.9995 - val_loss: 10.4537 - val_crf_viterbi_accuracy: 0.9908\n",
      " - f1: 92.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.58      0.29      0.39        24\n",
      "         LOC       0.95      0.93      0.94      4733\n",
      "         ORG       0.91      0.90      0.90      2740\n",
      "         PER       0.93      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.84      0.76      0.79     10055\n",
      "weighted avg       0.93      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.933813\n",
      "Epoch 42/50\n",
      "56268/56268 [==============================] - 487s 9ms/step - loss: 10.4766 - crf_viterbi_accuracy: 0.9994 - val_loss: 10.4552 - val_crf_viterbi_accuracy: 0.9913\n",
      " - f1: 93.36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.46      0.25      0.32        24\n",
      "         LOC       0.94      0.95      0.95      4733\n",
      "         ORG       0.93      0.90      0.92      2740\n",
      "         PER       0.95      0.92      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.93      0.93     10055\n",
      "   macro avg       0.82      0.75      0.78     10055\n",
      "weighted avg       0.94      0.93      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.933813\n",
      "Epoch 43/50\n",
      "56268/56268 [==============================] - 501s 9ms/step - loss: 10.4764 - crf_viterbi_accuracy: 0.9996 - val_loss: 10.4552 - val_crf_viterbi_accuracy: 0.9912\n",
      " - f1: 93.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.62      0.21      0.31        24\n",
      "         LOC       0.95      0.94      0.95      4733\n",
      "         ORG       0.92      0.90      0.91      2740\n",
      "         PER       0.95      0.92      0.94      2558\n",
      "\n",
      "   micro avg       0.94      0.93      0.93     10055\n",
      "   macro avg       0.86      0.74      0.78     10055\n",
      "weighted avg       0.94      0.93      0.93     10055\n",
      "\n",
      "f1_score improved from 0.933813 to 0.934223, saving model to best_model.h5\n",
      "Epoch 44/50\n",
      "56268/56268 [==============================] - 506s 9ms/step - loss: 10.4767 - crf_viterbi_accuracy: 0.9993 - val_loss: 10.4545 - val_crf_viterbi_accuracy: 0.9909\n",
      " - f1: 93.14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.54      0.29      0.38        24\n",
      "         LOC       0.94      0.94      0.94      4733\n",
      "         ORG       0.93      0.90      0.91      2740\n",
      "         PER       0.95      0.93      0.94      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.84      0.76      0.79     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.934223\n",
      "Epoch 45/50\n",
      "56268/56268 [==============================] - 501s 9ms/step - loss: 10.4767 - crf_viterbi_accuracy: 0.9993 - val_loss: 10.4529 - val_crf_viterbi_accuracy: 0.9914\n",
      " - f1: 93.47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.58      0.29      0.39        24\n",
      "         LOC       0.95      0.94      0.94      4733\n",
      "         ORG       0.93      0.90      0.92      2740\n",
      "         PER       0.95      0.93      0.94      2558\n",
      "\n",
      "   micro avg       0.94      0.93      0.93     10055\n",
      "   macro avg       0.85      0.77      0.80     10055\n",
      "weighted avg       0.94      0.93      0.93     10055\n",
      "\n",
      "f1_score improved from 0.934223 to 0.934716, saving model to best_model.h5\n",
      "Epoch 46/50\n",
      "56268/56268 [==============================] - 491s 9ms/step - loss: 10.4763 - crf_viterbi_accuracy: 0.9997 - val_loss: 10.4550 - val_crf_viterbi_accuracy: 0.9909\n",
      " - f1: 93.15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.44      0.29      0.35        24\n",
      "         LOC       0.95      0.93      0.94      4733\n",
      "         ORG       0.92      0.90      0.91      2740\n",
      "         PER       0.94      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.94      0.92      0.93     10055\n",
      "   macro avg       0.81      0.77      0.79     10055\n",
      "weighted avg       0.94      0.92      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.934716\n",
      "Epoch 47/50\n",
      "56268/56268 [==============================] - 491s 9ms/step - loss: 10.4765 - crf_viterbi_accuracy: 0.9995 - val_loss: 10.4540 - val_crf_viterbi_accuracy: 0.9908\n",
      " - f1: 92.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.78      0.29      0.42        24\n",
      "         LOC       0.94      0.95      0.94      4733\n",
      "         ORG       0.91      0.91      0.91      2740\n",
      "         PER       0.92      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10055\n",
      "   macro avg       0.89      0.77      0.80     10055\n",
      "weighted avg       0.93      0.93      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.934716\n",
      "Epoch 48/50\n",
      "56268/56268 [==============================] - 526s 9ms/step - loss: 10.4766 - crf_viterbi_accuracy: 0.9994 - val_loss: 10.4541 - val_crf_viterbi_accuracy: 0.9913\n",
      " - f1: 93.43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.80      0.17      0.28        24\n",
      "         LOC       0.95      0.94      0.95      4733\n",
      "         ORG       0.92      0.90      0.91      2740\n",
      "         PER       0.95      0.92      0.94      2558\n",
      "\n",
      "   micro avg       0.94      0.93      0.93     10055\n",
      "   macro avg       0.91      0.73      0.77     10055\n",
      "weighted avg       0.94      0.93      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.934716\n",
      "Epoch 49/50\n",
      "56268/56268 [==============================] - 535s 10ms/step - loss: 10.4765 - crf_viterbi_accuracy: 0.9995 - val_loss: 10.4558 - val_crf_viterbi_accuracy: 0.9905\n",
      " - f1: 92.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.83      0.21      0.33        24\n",
      "         LOC       0.95      0.94      0.94      4733\n",
      "         ORG       0.91      0.91      0.91      2740\n",
      "         PER       0.92      0.93      0.93      2558\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10055\n",
      "   macro avg       0.90      0.75      0.78     10055\n",
      "weighted avg       0.93      0.93      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.934716\n",
      "Epoch 50/50\n",
      "56268/56268 [==============================] - 496s 9ms/step - loss: 10.4765 - crf_viterbi_accuracy: 0.9994 - val_loss: 10.4535 - val_crf_viterbi_accuracy: 0.9912\n",
      " - f1: 93.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.60      0.12      0.21        24\n",
      "         LOC       0.95      0.94      0.95      4733\n",
      "         ORG       0.92      0.90      0.91      2740\n",
      "         PER       0.94      0.93      0.94      2558\n",
      "\n",
      "   micro avg       0.94      0.93      0.93     10055\n",
      "   macro avg       0.85      0.72      0.75     10055\n",
      "weighted avg       0.94      0.93      0.93     10055\n",
      "\n",
      "f1_score did not improve from 0.934716\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "results = model.fit(X_train, y_train, batch_size = 32, epochs = 50, validation_split = 0.1, verbose = 1, callbacks=[F1score(use_char=False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_crf_model = load_model('./best_model.h5', custom_objects={'CRF':CRF,\n",
    "                                                  'crf_loss':crf_loss,\n",
    "                                                  'crf_viterbi_accuracy':crf_viterbi_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token          |right value|predicted value\n",
      "-----------------------------------\n",
      "由                : O       O\n",
      "“                : B-ORG   B-ORG\n",
      "青                : I-ORG   I-ORG\n",
      "岛                : I-ORG   I-ORG\n",
      "”                : I-ORG   I-ORG\n",
      "号                : I-ORG   I-ORG\n",
      "导                : I-ORG   I-ORG\n",
      "弹                : I-ORG   I-ORG\n",
      "驱                : I-ORG   I-ORG\n",
      "逐                : I-ORG   I-ORG\n",
      "舰                : I-ORG   I-ORG\n",
      "和                : O       O\n",
      "“                : B-ORG   B-ORG\n",
      "世                : I-ORG   I-ORG\n",
      "昌                : I-ORG   I-ORG\n",
      "”                : I-ORG   I-ORG\n",
      "号                : I-ORG   I-ORG\n",
      "综                : I-ORG   I-ORG\n",
      "合                : I-ORG   I-ORG\n",
      "训                : I-ORG   I-ORG\n",
      "练                : I-ORG   I-ORG\n",
      "舰                : I-ORG   I-ORG\n",
      "组                : O       O\n",
      "成                : O       O\n",
      "的                : O       O\n",
      "中                : B-ORG   B-ORG\n",
      "国                : I-ORG   I-ORG\n",
      "海                : I-ORG   I-ORG\n",
      "军                : I-ORG   I-ORG\n",
      "舰                : I-ORG   I-ORG\n",
      "艇                : I-ORG   I-ORG\n",
      "编                : I-ORG   I-ORG\n",
      "队                : I-ORG   I-ORG\n",
      "今                : O       O\n",
      "天                : O       O\n",
      "上                : O       O\n",
      "午                : O       O\n",
      "驶                : O       O\n",
      "抵                : O       O\n",
      "奥                : B-LOC   B-LOC\n",
      "克                : I-LOC   I-LOC\n",
      "兰                : I-LOC   I-LOC\n",
      "港                : I-LOC   I-LOC\n",
      "，                : O       O\n",
      "开                : O       O\n",
      "始                : O       O\n",
      "对                : O       O\n",
      "新                : B-LOC   B-LOC\n",
      "西                : I-LOC   I-LOC\n",
      "兰                : I-LOC   I-LOC\n",
      "为                : O       O\n",
      "期                : O       O\n",
      "３                : O       O\n",
      "天                : O       O\n",
      "的                : O       O\n",
      "友                : O       O\n",
      "好                : O       O\n",
      "访                : O       O\n",
      "问                : O       O\n",
      "。                : O       O\n"
     ]
    }
   ],
   "source": [
    "i=1 # sample index for test predicted value\n",
    "y_predicted = bilstm_crf_model.predict(np.array([X_test[i]])) \n",
    "y_predicted = np.argmax(y_predicted, axis=-1) # one-hot encoding to integer encoding.\n",
    "true = np.argmax(y_test[i], -1) \n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"token\", \"right value\", \"predicted value\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
    "    if w != 0: # except PAD value\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[w], index_to_ner[t], index_to_ner[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluate the model\n",
    "### F1-score / classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5341"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score = F1score(use_char=False)\n",
    "\n",
    "y_predicted = bilstm_crf_model.predict([X_test])\n",
    "pred_tags = f1score.sequences_to_tags(y_predicted)\n",
    "test_tags = f1score.sequences_to_tags(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 93.6%\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         GPE       0.56      0.33      0.41        55\n",
      "         LOC       0.96      0.95      0.95     12126\n",
      "         ORG       0.93      0.91      0.92      6819\n",
      "         PER       0.93      0.92      0.92      6308\n",
      "\n",
      "   micro avg       0.94      0.93      0.94     25308\n",
      "   macro avg       0.85      0.78      0.80     25308\n",
      "weighted avg       0.94      0.93      0.94     25308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_tags, pred_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3327d6982444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbilstm_crf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'crf_viterbi_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_crf_viterbi_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(bilstm_crf_model.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(results.history['crf_viterbi_accuracy'])\n",
    "plt.plot(results.history['val_crf_viterbi_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
